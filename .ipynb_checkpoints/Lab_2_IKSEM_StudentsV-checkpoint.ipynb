{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSCRK54nDGEU"
   },
   "source": [
    "---\n",
    "University Paris 1 Panthéon-Sorbonne \n",
    "\n",
    "Machine Learning\n",
    "\n",
    "Dr. Nourhène BEN RABAH\n",
    "\n",
    "---\n",
    "\n",
    "# Lab 2: Data scaling, data normalization and data transformation \n",
    "\n",
    "#### You must send the notebook completed during the session on Discord.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercice1.\n",
    "\n",
    "You will apply label encoding for the vote column and On-hot encoding for the region column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pnd\n",
    "\n",
    "dfCategories = pnd.DataFrame (\n",
    "    [ ['male', 'from US', 'uses Safari', 'approves'], \n",
    "      ['female', 'from Europe', 'uses Firefox', 'disaproves'] ,\n",
    "      ['female', 'from US', 'uses Safari', 'approves'],\n",
    "      ['male', 'from Europe', 'uses Safari', 'approves'],\n",
    "      ['female', 'from US', 'uses Firefox', 'disaproves'] ,\n",
    "      ['male', 'from Europe', 'uses Chrome', 'disaproves'] , \n",
    "      ['female', 'from Asia', 'uses Chrome', 'approves'],\n",
    "      ['male', 'from Asia', 'uses Chrome', 'approves'] ],\n",
    "    columns=['sex', 'region','browser', 'vote' ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Colors: [0 1 0 0 1 1 0 0]\n",
      "Encoded Data:\n",
      "   from Asia  from Europe  from US\n",
      "0          0            0        1\n",
      "1          0            1        0\n",
      "2          0            0        1\n",
      "3          0            1        0\n",
      "4          0            0        1\n",
      "5          0            1        0\n",
      "6          1            0        0\n",
      "7          1            0        0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform data\n",
    "encoded_colors = label_encoder.fit_transform(dfCategories['vote'])\n",
    "\n",
    "# Print encoded data\n",
    "print(\"Encoded Colors:\", encoded_colors)\n",
    "\n",
    "one_hot_encoded = pnd.get_dummies(dfCategories['region'])\n",
    "\n",
    "# Print One-Hot Encoded data\n",
    "print(\"Encoded Data:\")\n",
    "print(one_hot_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercice2. IoT attack detection with Danmini.csv\n",
    "\n",
    "In this exercice, you will import the Danmini Dataset (Danmini. csv) which contains data to predict whether the IoT attack is bashlite or Mirai on a Danmini Doorbel device. \n",
    "\n",
    "- 1) Start by discovering the dataset (number of rows, columns, column types, target value to predict, see first rows and last rows, ... (as we did in the first lab) \n",
    "- 2) Data cleaning (see missing values and perform data cleaning)\n",
    "- 3) Data scaling, normalization \n",
    "- 4) data transformation (encode the numerical values). \n",
    "\n",
    "After these steps you can train your first ML algo, which we will discover in the next session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows :  436\n",
      "Columns :  12\n",
      "Column types : ID        object\n",
      "M/F       object\n",
      "Hand      object\n",
      "Age        int64\n",
      "Educ     float64\n",
      "SES      float64\n",
      "MMSE     float64\n",
      "CDR      float64\n",
      "eTIV       int64\n",
      "nWBV     float64\n",
      "ASF      float64\n",
      "Delay    float64\n",
      "dtype: object\n",
      "Ten first rows : \n",
      "                ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  \\\n",
      "0  OAS1_0001_MR1   F    R   74   2.0  3.0  29.0  0.0  1344  0.743  1.306   \n",
      "1  OAS1_0002_MR1   F    R   55   4.0  1.0  29.0  0.0  1147  0.810  1.531   \n",
      "2  OAS1_0003_MR1   F    R   73   4.0  3.0  27.0  0.5  1454  0.708  1.207   \n",
      "3  OAS1_0004_MR1   M    R   28   NaN  NaN   NaN  NaN  1588  0.803  1.105   \n",
      "4  OAS1_0005_MR1   M    R   18   NaN  NaN   NaN  NaN  1737  0.848  1.010   \n",
      "5  OAS1_0006_MR1   F    R   24   NaN  NaN   NaN  NaN  1131  0.862  1.551   \n",
      "6  OAS1_0007_MR1   M    R   21   NaN  NaN   NaN  NaN  1516  0.830  1.157   \n",
      "7  OAS1_0009_MR1   F    R   20   NaN  NaN   NaN  NaN  1505  0.843  1.166   \n",
      "8  OAS1_0010_MR1   M    R   74   5.0  2.0  30.0  0.0  1636  0.689  1.073   \n",
      "9  OAS1_0011_MR1   F    R   52   3.0  2.0  30.0  0.0  1321  0.827  1.329   \n",
      "\n",
      "   Delay  \n",
      "0    NaN  \n",
      "1    NaN  \n",
      "2    NaN  \n",
      "3    NaN  \n",
      "4    NaN  \n",
      "5    NaN  \n",
      "6    NaN  \n",
      "7    NaN  \n",
      "8    NaN  \n",
      "9    NaN  \n",
      "Ten last rows : \n",
      "                 ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  \\\n",
      "426  OAS1_0202_MR2   F    R   23   NaN  NaN   NaN  NaN  1548  0.861  1.134   \n",
      "427  OAS1_0230_MR2   F    R   19   NaN  NaN   NaN  NaN  1577  0.849  1.113   \n",
      "428  OAS1_0236_MR2   F    R   20   NaN  NaN   NaN  NaN  1222  0.872  1.436   \n",
      "429  OAS1_0239_MR2   F    R   29   NaN  NaN   NaN  NaN  1438  0.822  1.221   \n",
      "430  OAS1_0249_MR2   F    R   28   NaN  NaN   NaN  NaN  1215  0.865  1.444   \n",
      "431  OAS1_0285_MR2   M    R   20   NaN  NaN   NaN  NaN  1469  0.847  1.195   \n",
      "432  OAS1_0353_MR2   M    R   22   NaN  NaN   NaN  NaN  1684  0.790  1.042   \n",
      "433  OAS1_0368_MR2   M    R   22   NaN  NaN   NaN  NaN  1580  0.856  1.111   \n",
      "434  OAS1_0379_MR2   F    R   20   NaN  NaN   NaN  NaN  1262  0.861  1.390   \n",
      "435  OAS1_0395_MR2   F    R   26   NaN  NaN   NaN  NaN  1283  0.834  1.368   \n",
      "\n",
      "     Delay  \n",
      "426   21.0  \n",
      "427   24.0  \n",
      "428    3.0  \n",
      "429   40.0  \n",
      "430    3.0  \n",
      "431    2.0  \n",
      "432   40.0  \n",
      "433   89.0  \n",
      "434    2.0  \n",
      "435   39.0  \n",
      "ID         0\n",
      "M/F        0\n",
      "Hand       0\n",
      "Age        0\n",
      "Educ     201\n",
      "SES      220\n",
      "MMSE     201\n",
      "CDR      201\n",
      "eTIV       0\n",
      "nWBV       0\n",
      "ASF        0\n",
      "Delay    416\n",
      "dtype: int64\n",
      "Number of rows :  373\n",
      "Columns :  15\n",
      "Column types : Subject ID     object\n",
      "MRI ID         object\n",
      "Group          object\n",
      "Visit           int64\n",
      "MR Delay        int64\n",
      "M/F            object\n",
      "Hand           object\n",
      "Age             int64\n",
      "EDUC            int64\n",
      "SES           float64\n",
      "MMSE          float64\n",
      "CDR           float64\n",
      "eTIV            int64\n",
      "nWBV          float64\n",
      "ASF           float64\n",
      "dtype: object\n",
      "Ten first rows : \n",
      "    Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  EDUC  \\\n",
      "0  OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87    14   \n",
      "1  OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88    14   \n",
      "2  OAS2_0002  OAS2_0002_MR1     Demented      1         0   M    R   75    12   \n",
      "3  OAS2_0002  OAS2_0002_MR2     Demented      2       560   M    R   76    12   \n",
      "4  OAS2_0002  OAS2_0002_MR3     Demented      3      1895   M    R   80    12   \n",
      "5  OAS2_0004  OAS2_0004_MR1  Nondemented      1         0   F    R   88    18   \n",
      "6  OAS2_0004  OAS2_0004_MR2  Nondemented      2       538   F    R   90    18   \n",
      "7  OAS2_0005  OAS2_0005_MR1  Nondemented      1         0   M    R   80    12   \n",
      "8  OAS2_0005  OAS2_0005_MR2  Nondemented      2      1010   M    R   83    12   \n",
      "9  OAS2_0005  OAS2_0005_MR3  Nondemented      3      1603   M    R   85    12   \n",
      "\n",
      "   SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "0  2.0  27.0  0.0  1987  0.696  0.883  \n",
      "1  2.0  30.0  0.0  2004  0.681  0.876  \n",
      "2  NaN  23.0  0.5  1678  0.736  1.046  \n",
      "3  NaN  28.0  0.5  1738  0.713  1.010  \n",
      "4  NaN  22.0  0.5  1698  0.701  1.034  \n",
      "5  3.0  28.0  0.0  1215  0.710  1.444  \n",
      "6  3.0  27.0  0.0  1200  0.718  1.462  \n",
      "7  4.0  28.0  0.0  1689  0.712  1.039  \n",
      "8  4.0  29.0  0.5  1701  0.711  1.032  \n",
      "9  4.0  30.0  0.0  1699  0.705  1.033  \n",
      "Ten last rows : \n",
      "     Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  \\\n",
      "363  OAS2_0183  OAS2_0183_MR3  Nondemented      3       732   F    R   68   \n",
      "364  OAS2_0183  OAS2_0183_MR4  Nondemented      4      2107   F    R   72   \n",
      "365  OAS2_0184  OAS2_0184_MR1     Demented      1         0   F    R   72   \n",
      "366  OAS2_0184  OAS2_0184_MR2     Demented      2       553   F    R   73   \n",
      "367  OAS2_0185  OAS2_0185_MR1     Demented      1         0   M    R   80   \n",
      "368  OAS2_0185  OAS2_0185_MR2     Demented      2       842   M    R   82   \n",
      "369  OAS2_0185  OAS2_0185_MR3     Demented      3      2297   M    R   86   \n",
      "370  OAS2_0186  OAS2_0186_MR1  Nondemented      1         0   F    R   61   \n",
      "371  OAS2_0186  OAS2_0186_MR2  Nondemented      2       763   F    R   63   \n",
      "372  OAS2_0186  OAS2_0186_MR3  Nondemented      3      1608   F    R   65   \n",
      "\n",
      "     EDUC  SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
      "363    13  2.0  30.0  0.0  1506  0.740  1.165  \n",
      "364    13  2.0  30.0  0.0  1510  0.723  1.162  \n",
      "365    16  3.0  24.0  0.5  1354  0.733  1.296  \n",
      "366    16  3.0  21.0  1.0  1351  0.708  1.299  \n",
      "367    16  1.0  28.0  0.5  1704  0.711  1.030  \n",
      "368    16  1.0  28.0  0.5  1693  0.694  1.037  \n",
      "369    16  1.0  26.0  0.5  1688  0.675  1.040  \n",
      "370    13  2.0  30.0  0.0  1319  0.801  1.331  \n",
      "371    13  2.0  30.0  0.0  1327  0.796  1.323  \n",
      "372    13  2.0  30.0  0.0  1333  0.801  1.317  \n",
      "Subject ID     0\n",
      "MRI ID         0\n",
      "Group          0\n",
      "Visit          0\n",
      "MR Delay       0\n",
      "M/F            0\n",
      "Hand           0\n",
      "Age            0\n",
      "EDUC           0\n",
      "SES           19\n",
      "MMSE           2\n",
      "CDR            0\n",
      "eTIV           0\n",
      "nWBV           0\n",
      "ASF            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The Target value to predict is CDR \n",
    "# CDR - Clinical Dementia Rating (0 = no dementia, 0.5 = very mild AD, 1 = mild AD, 2 = moderate AD, 3 = severe AD)\n",
    "\n",
    "# Datasets\n",
    "df=pd.read_csv('oasis_cross-sectional.csv', delimiter=',')\n",
    "df2=pd.read_csv('oasis_longitudinal.csv', delimiter=',')\n",
    "\n",
    "#1# #DESCRIPTION OF DATA\n",
    "# A # ### Data df (1st Dataset) ###\n",
    "#Number of rows\n",
    "number_of_rows = len(df)\n",
    "print(\"Number of rows : \",number_of_rows)\n",
    "#Columns\n",
    "columns = df.shape[1]\n",
    "print(\"Columns : \",columns)\n",
    "#Columns Type\n",
    "column_types = df.dtypes\n",
    "print(\"Column types :\", column_types)\n",
    "# ten First rows\n",
    "ten_first_rows = df.iloc[:10]\n",
    "print(\"Ten first rows : \\n \", ten_first_rows)\n",
    "# ten Last rows\n",
    "ten_last_rows = df.tail(10)\n",
    "print(\"Ten last rows : \\n\", ten_last_rows)\n",
    "#We look at the null values in df\n",
    "print(df.isna().sum())\n",
    "\n",
    "# A # ### Data df2 (2nd Dataset) ###\n",
    "#Number of rows\n",
    "number_of_rows = len(df2)\n",
    "print(\"Number of rows : \",number_of_rows)\n",
    "#Columns\n",
    "columns = df2.shape[1]\n",
    "print(\"Columns : \",columns)\n",
    "#Columns Type\n",
    "column_types = df2.dtypes\n",
    "print(\"Column types :\", column_types)\n",
    "# ten First rows\n",
    "ten_first_rows = df2.iloc[:10]\n",
    "print(\"Ten first rows : \\n \", ten_first_rows)\n",
    "# ten Last rows\n",
    "ten_last_rows = df2.tail(10)\n",
    "print(\"Ten last rows : \\n\", ten_last_rows)\n",
    "#We look at the null values in df_final\n",
    "print(df2.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Age        Educ        SES        MMSE         CDR         eTIV  \\\n",
      "count  809.000000  608.000000  570.00000  606.000000  608.000000   809.000000   \n",
      "mean    63.186650   10.184211    2.47193   27.234323    0.288651  1484.782447   \n",
      "std     23.117511    6.058388    1.12805    3.687980    0.377697   166.911689   \n",
      "min     18.000000    1.000000    1.00000    4.000000    0.000000  1106.000000   \n",
      "25%     49.000000    4.000000    2.00000   26.000000    0.000000  1361.000000   \n",
      "50%     72.000000   12.000000    2.00000   29.000000    0.000000  1475.000000   \n",
      "75%     80.000000   16.000000    3.00000   30.000000    0.500000  1583.000000   \n",
      "max     98.000000   23.000000    5.00000   30.000000    2.000000  2004.000000   \n",
      "\n",
      "             nWBV         ASF  \n",
      "count  809.000000  809.000000  \n",
      "mean     0.763037    1.197311  \n",
      "std      0.059401    0.133031  \n",
      "min      0.644000    0.876000  \n",
      "25%      0.715000    1.108000  \n",
      "50%      0.754000    1.190000  \n",
      "75%      0.817000    1.290000  \n",
      "max      0.893000    1.587000  \n",
      "df_final head:                ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF\n",
      "0  OAS1_0001_MR1   F    R   74   2.0  3.0  29.0  0.0  1344  0.743  1.306\n",
      "1  OAS1_0002_MR1   F    R   55   4.0  1.0  29.0  0.0  1147  0.810  1.531\n",
      "2  OAS1_0003_MR1   F    R   73   4.0  3.0  27.0  0.5  1454  0.708  1.207\n",
      "3  OAS1_0004_MR1   M    R   28   NaN  NaN   NaN  NaN  1588  0.803  1.105\n",
      "4  OAS1_0005_MR1   M    R   18   NaN  NaN   NaN  NaN  1737  0.848  1.010\n",
      "df_final tail:              ID M/F Hand  Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF\n",
      "368  OAS2_0185   M    R   82  16.0  1.0  28.0  0.5  1693  0.694  1.037\n",
      "369  OAS2_0185   M    R   86  16.0  1.0  26.0  0.5  1688  0.675  1.040\n",
      "370  OAS2_0186   F    R   61  13.0  2.0  30.0  0.0  1319  0.801  1.331\n",
      "371  OAS2_0186   F    R   63  13.0  2.0  30.0  0.0  1327  0.796  1.323\n",
      "372  OAS2_0186   F    R   65  13.0  2.0  30.0  0.0  1333  0.801  1.317\n",
      "0\n",
      "M/F      0\n",
      "Age      0\n",
      "Educ     0\n",
      "SES     38\n",
      "MMSE     2\n",
      "CDR      0\n",
      "eTIV     0\n",
      "nWBV     0\n",
      "ASF      0\n",
      "dtype: int64\n",
      "One-Hot Encoded Gender Data:\n",
      "     F  M\n",
      "0    1  0\n",
      "1    1  0\n",
      "2    1  0\n",
      "8    0  1\n",
      "9    1  0\n",
      "..  .. ..\n",
      "368  0  1\n",
      "369  0  1\n",
      "370  1  0\n",
      "371  1  0\n",
      "372  1  0\n",
      "\n",
      "[570 rows x 2 columns]\n",
      "df_final\n",
      "   Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  F  M\n",
      "0   74   2.0  3.0  29.0  0.0  1344  0.743  1.306  1  0\n",
      "1   55   4.0  1.0  29.0  0.0  1147  0.810  1.531  1  0\n",
      "2   73   4.0  3.0  27.0  0.5  1454  0.708  1.207  1  0\n",
      "8   74   5.0  2.0  30.0  0.0  1636  0.689  1.073  0  1\n",
      "9   52   3.0  2.0  30.0  0.0  1321  0.827  1.329  1  0\n",
      "df_final\n",
      "   Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  F  M\n",
      "0   74   2.0  3.0  29.0    0  1344  0.743  1.306  1  0\n",
      "1   55   4.0  1.0  29.0    0  1147  0.810  1.531  1  0\n",
      "2   73   4.0  3.0  27.0    1  1454  0.708  1.207  1  0\n",
      "8   74   5.0  2.0  30.0    0  1636  0.689  1.073  0  1\n",
      "9   52   3.0  2.0  30.0    0  1321  0.827  1.329  1  0\n",
      "df_final\n",
      "   Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  F  M\n",
      "0   74   2.0    2  29.0    0  1344  0.743  1.306  1  0\n",
      "1   55   4.0    0  29.0    0  1147  0.810  1.531  1  0\n",
      "2   73   4.0    2  27.0    1  1454  0.708  1.207  1  0\n",
      "8   74   5.0    1  30.0    0  1636  0.689  1.073  0  1\n",
      "9   52   3.0    1  30.0    0  1321  0.827  1.329  1  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Datasets\n",
    "df=pd.read_csv('oasis_cross-sectional.csv', delimiter=',')\n",
    "df2=pd.read_csv('oasis_longitudinal.csv', delimiter=',')\n",
    "\n",
    "#The first and second datasets have the same data with the second having more attributes\n",
    "#We prepare the dataset df2 for merging with df dataset, by dropping and renaming columns\n",
    "#2) 4) Data Cleaning and Encoding\n",
    "df2=df2.rename(columns={\"EDUC\" : \"Educ\"})\n",
    "df2=df2.rename(columns={\"Subject ID\" : \"ID\"})\n",
    "df=df.drop(columns=['Delay'])\n",
    "#MR delay is an unknown parameter, Group is duplicated with CDR it says if a person has alzheimer or not but CDR already\n",
    "#indicates if one has Alzheimer, Visit is the number of visits and MRI id is the MRI id \n",
    "df2=df2.drop(columns=['Group','Visit', 'MR Delay', 'MRI ID'])\n",
    "df_final= pd.concat([df, df2], axis=0)\n",
    "#Looking at the combined dataset\n",
    "print(df_final.describe())\n",
    "print(\"df_final head: \",df_final.head(5))\n",
    "print(\"df_final tail: \",df_final.tail(5))\n",
    "#We are dropping the null CDR as CDR is the target value and cannot have null values\n",
    "df_final = df_final.dropna(subset = ['CDR'])\n",
    "#The ID has no correlation with CDR so we drop the column\n",
    "df_final=df_final.drop(columns='ID')\n",
    "#In the dataset There are only right handed people so we drop the column\n",
    "subject_left_handed = len(df_final[df_final['Hand'] != 'R'])\n",
    "print(subject_left_handed)\n",
    "df_final=df_final.drop(columns='Hand')\n",
    "#We are looking at the remaining null values after dropping null CDR\n",
    "print(df_final.isna().sum())\n",
    "#SES is composed of discrete int values which represents the socioeconomical status of the person (from 1=highest status\n",
    "#to 5=lower status), it is not pertinent to do a mean or median on this column and there are only 38 values missing\n",
    "#which is negligeable\n",
    "df_final=df_final.dropna(subset=['SES'])\n",
    "\n",
    "#After this drop there is no more null values, We can start encoding the values\n",
    "\n",
    "# Perform One-Hot Encoding on M/F (Gender) column, append the one hot encoded columns and delete the M/F column\n",
    "one_hot_encoded_gender = pd.get_dummies(df_final['M/F'])\n",
    "print(\"One-Hot Encoded Gender Data:\")\n",
    "print(one_hot_encoded_gender)\n",
    "df_final= pd.concat([df_final, one_hot_encoded_gender], axis=1)\n",
    "df_final= df_final.drop(columns=['M/F'])\n",
    "print(\"df_final\")\n",
    "print(df_final.head(5))\n",
    "\n",
    "\n",
    "#Perform Label Encoding on CDR (Clinical Dementia Rating) column, we perform label encoding because the numbers \n",
    "#represent the degree of dementia of a person\n",
    "label_encoder = LabelEncoder()\n",
    "df_final['encoded_class_cdr'] = label_encoder.fit_transform(df_final['CDR'])\n",
    "df_final['CDR']=df_final['encoded_class_cdr']\n",
    "df_final=df_final.drop(columns=['encoded_class_cdr'])\n",
    "print(\"df_final\")\n",
    "print(df_final.head(5))\n",
    "\n",
    "#Perform Label Encoding on SES (from 1=highest status to 5=lower status), it is a hierarchical value so it is pertinent\n",
    "#to perform label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "df_final['encoded_class_ses'] = label_encoder.fit_transform(df_final['SES'])\n",
    "df_final['SES']=df_final['encoded_class_ses']\n",
    "df_final=df_final.drop(columns=['encoded_class_ses'])\n",
    "print(\"df_final\")\n",
    "print(df_final.head(5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data:\n",
      "      Age  Educ  SES  MMSE  CDR  eTIV   nWBV    ASF  F  M\n",
      "0     74   2.0    2  29.0    0  1344  0.743  1.306  1  0\n",
      "1     55   4.0    0  29.0    0  1147  0.810  1.531  1  0\n",
      "2     73   4.0    2  27.0    1  1454  0.708  1.207  1  0\n",
      "8     74   5.0    1  30.0    0  1636  0.689  1.073  0  1\n",
      "9     52   3.0    1  30.0    0  1321  0.827  1.329  1  0\n",
      "..   ...   ...  ...   ...  ...   ...    ...    ... .. ..\n",
      "368   82  16.0    0  28.0    1  1693  0.694  1.037  0  1\n",
      "369   86  16.0    0  26.0    1  1688  0.675  1.040  0  1\n",
      "370   61  13.0    1  30.0    0  1319  0.801  1.331  1  0\n",
      "371   63  13.0    1  30.0    0  1327  0.796  1.323  1  0\n",
      "372   65  13.0    1  30.0    0  1333  0.801  1.317  1  0\n",
      "\n",
      "[570 rows x 10 columns]\n",
      "Normalized Data:\n",
      "           Age      Educ   SES      MMSE       CDR      eTIV      nWBV  \\\n",
      "0    0.630769  0.045455  0.50  0.961538  0.000000  0.265033  0.502538   \n",
      "1    0.338462  0.136364  0.00  0.961538  0.000000  0.045657  0.842640   \n",
      "2    0.615385  0.136364  0.50  0.884615  0.333333  0.387528  0.324873   \n",
      "3    0.630769  0.181818  0.25  1.000000  0.000000  0.590200  0.228426   \n",
      "4    0.292308  0.090909  0.25  1.000000  0.000000  0.239421  0.928934   \n",
      "..        ...       ...   ...       ...       ...       ...       ...   \n",
      "565  0.753846  0.681818  0.00  0.923077  0.333333  0.653675  0.253807   \n",
      "566  0.815385  0.681818  0.00  0.846154  0.333333  0.648107  0.157360   \n",
      "567  0.430769  0.545455  0.25  1.000000  0.000000  0.237194  0.796954   \n",
      "568  0.461538  0.545455  0.25  1.000000  0.000000  0.246102  0.771574   \n",
      "569  0.492308  0.545455  0.25  1.000000  0.000000  0.252784  0.796954   \n",
      "\n",
      "          ASF    F    M  \n",
      "0    0.604782  1.0  0.0  \n",
      "1    0.921238  1.0  0.0  \n",
      "2    0.465541  1.0  0.0  \n",
      "3    0.277075  0.0  1.0  \n",
      "4    0.637131  1.0  0.0  \n",
      "..        ...  ...  ...  \n",
      "565  0.226442  0.0  1.0  \n",
      "566  0.230661  0.0  1.0  \n",
      "567  0.639944  1.0  0.0  \n",
      "568  0.628692  1.0  0.0  \n",
      "569  0.620253  1.0  0.0  \n",
      "\n",
      "[570 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#3) Data normalization\n",
    "#There ranges between the values such as eTIV, nWBV or Educ is wide so we found pertinent to use\n",
    "#as seen in the df_final.describe() before\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit the scaler to the data and transform the data\n",
    "df_final_normalized = scaler.fit_transform(df_final)\n",
    "\n",
    "df_final_normalized = pd.DataFrame(df_final_normalized, columns=df_final.columns)\n",
    "print(\"Original Data:\\n\", df_final)\n",
    "print(\"Normalized Data:\\n\", df_final_normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Project \n",
    "\n",
    "Let's move on to phase 1. Data preparation: \n",
    "You'll prepare the data by performing operations such as data cleaning, data normalization and transformation,\n",
    "To do this, you'll need to:\n",
    " - Describe your data, (number of rows, columns, column types, target value to predict, see first rows and last rows, ... (as we did in the first lab). \n",
    "- Describe the data cleaning technique(s) used (justify the decisions made)\n",
    "- Describe the data normalization, scaling and transformation methods used and justify the decisions made. \n",
    "- The code must be commented and explained. \n",
    "\n",
    "= You must send me your notebooks before the end of session 2."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_1_ESIEECom_Campagnes_de_publicité.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
